\section{Experimental settings}
The data used for generating and testing cache replacement policies was acquired from \citep{data}. The program used to simulate cache replacement policies expects a linear array of integers as input data, where each integer represents a different page. So the data from the trace files was prepared in the following way: each page was assigned a number, starting from 0 and increasing by 1 for each first appearance of a page. Subsequent appearances of the same page were referenced with its original assigned number. 

The fitness function which will be used in all the runs is simply the number of hits the strategy gets over a run.

The algorithm parameters are: selection operator, mutation rate, population size, codon count and maximum number of wrappings.

The only problem parameter is the cache size, which is the number of frames in the cache. This number will be varied to determine how well grammatical evolution performs on different cache sizes.

The two variants of the genetic algorithm that we will test, which correspond to the two types of the selection operator, are the steady-state algorithm with tournament selection and the generational algorithm with fitness-proportional selection and the elitism count of one. The number one was chosen for the elitism count since the goal of this parameter is only to preserve the best solution between generations. We still want to search the solution space as much as possible.

To avoid the combinatorial explosion of testing the Cartesian product of different values of the algorithm parameters, each parameter will be optimised one-dimensionally. This means that we will choose some average values for all the parameters, sort the algorithm parameters by our estimate of their importance from the most important to the least important, and then optimize them one by one. The problem parameter, which is the cache size, will also be set to an average, non-extreme value.

The parameters will be tested in the following order: selection operator (which is expected to have a tremendous impact on the final results), mutation rate, population size, codon count and maximum number of wrappings (which is expected to have a minimal impact on the final results).

The trace file used for parameter optimization was the 'swim.trace' file, and the data used for parameter optimization consisted of the first 20000 requests. Each page index was modulated by 1000. The reason behind this decision was the goal to provide a unique setting for generating and testing our strategies, because it felt natural to train them and test them using the data with the same number of different pages. Retrospectively speaking, tampering with the trace file data in this way may have turned out to be a bad idea and may have foiled the parameter optimization process, so this decision was abandoned once the actual experiments began. Still, I believe that the parameter optimization wasn't completely futile, and that it still merited some valuable information about good algorithm parameter values.

Since the genetic algorithm is inherently stochastic, each experiment will be repeated 10 times, and the median value of these runs will be used as the final result. If the median value turns out to be a bad measure for comparing different parameter configurations (for example, if the median value of multiple configurations is the same), then the average value will be used instead.

Once all the parameters have been optimized, the algorithm will be run using these parameters on different cache sizes, and the generated strategies will be compared to the classical heuristic strategies for cache management.

All the diagrams included in this chapter were generated using the \citep{box_plots}.