\section{Genetic algorithm}
\subsection{Basic principles}
Genetic algorithm is a metahueristic inspired by the Darwinian theory of evolution. The main idea is that, given a population in an environment with limited resources, competition for those resources causes natural selection \citep{eiben2015evolutionarycomputing}.  This principle is sometimes called 'survival of the fittest'. 

One of the first design choices in solving an optimisation problem using a genetic algorithm is individual representation. We can distinguish two different terms - genotype and phenotype. Genotype corresponds to the encoding of an individual. Variation operators (recombination and mutation) are applied on the genotype of an individual. In the process of evaluating an individual, its genotype is decoded onto its phenotype. Phenotype corresponds to the actual solution, and we determine how good of a solution one individual is by evaluating its phenotype using a fitness function.

\subsection{Genetic algorithm pseudocode}
The basic flow of a genetic algorithm is described as \citep{eiben2015evolutionarycomputing}:

\begin{algorithm}[]
\caption{Genetic algorithm}
\begin{algorithmic}[1]
\State $\text{initialise } \textit{population} \text{;}$
\State $\text{evaluate } \text{each solution};$
\State $\text{repeat while (} \textit{terminal condition} \text{ not satisfied)}$
\State $\indent \text{select } \textit{parents} \text{;}$
\State $\indent \text{recombine pairs of } \textit{parents} \text{;}$
\State $\indent \text{mutate acquired } \textit{children} \text{;}$
\State $\indent \text{evaluate } \textit{children} \text{;}$
\State $\indent \text{select individuals for next generation;}$
\State $\text{end while}$
\end{algorithmic}
\end{algorithm}

In line 1, we initialise the population. We can either initialise it with random solutions, or, if we know some good solutions which can be a good starting point for the evolutionary search process, we can seed it with those.

In line 2, we evaluate each solution using a fitness function. Fitness function is applied over the individual's phenotype, and it returns a measure of how good a solution is. In that case, the goal of the genetic algorithm is to find the solutions which maximize this measure. When solving some problems, it is much easier to determine how bad of a solution one individual is, rather than how good of a solution it is. In that case, fitness function returns a measure of how bad a solution is, and the goal of the genetic algorithm is to minimize this measure.

In line 3, we start the evolutionary loop. Each new iteration of this loop corresponds to a different generation of the population. This loop is stopped when some stopping criteria is satisfied. The simplest stopping criteria is reaching the predetermined number of iterations. If we know how good of a solution we need, we can also stop this loop once we find one such solution.  

In line 4, we select the parents which we will later recombine to get their offspring, which will be new candidate solutions. When choosing which individuals will be parents, we want to keep their fitness in mind. We want to choose the better individuals more often, in order to guide the evolutionary search towards better solutions. If we don't discriminate individuals over their fitness when selecting parents for future solutions, our evolutionary search can degrade into random search. On the other hand, we want to be able to choose the bad solutions to be parents as well, albeit with a low chance. If we chose only the good solutions to be parents, our search could become too greedy and get stuck in a local optimum. Two common ways of choosing parents for the offspring are fitness-proportional selection, where the chance of each individual being chosen is proportional to its fitness, and tournament selection, where a random subset of the population is taken into account, and then the best individual or the best two individuals in this subpopulation are chosen as parents. One popular variant of the tournament selection is initialising the subpopulation of size three, choosing the two best individuals as parents, and replacing the third individual (the worst one) with the offspring of the chosen parents \citep{cupic2019evolucijskoracunarstvo}.

In line 5, we recombine the genotypes of selected parents to get the genotype of their offspring. Recombination process can yield one or more offspring. The idea behind recombination is - if we chose a good genotype-phenotype mapping, we can expect that an individual's fitness will be coded into its genotype. Combining good solutions should yield even better solutions, if we choose the good parts of the first parent and good parts of the second parent, and then combine these good parts into a new solution. Of course, since the recombination process is random, we can also sometimes choose the bad part of the first parent and the bad part of the second parent to get an individual that is worse than its parents, but that isn't a significant problem, since we can also get good solutions which can guide the evolutionary search.

In line 6, we apply the mutation operator on newly constructed individuals, which are the result of the recombination process. The main idea behind mutation is that it should increase diversity of the population. Mutation operator should not be guided by some rule, instead, it should be random and unbiased \citep{eiben2015evolutionarycomputing}. If we don't include the mutation operator, or if we set the mutation rate to be too low, our search can get stuck in a local optimum. On the other hand, we don't want the mutation rate to be too large either. Since the new solutions are constructed from good solutions (with a high chance), and we expect that good solutions have their fitness coded into their genotypes, if the mutation operator is too disruptive, it can nullify the good results of the recombination, and degrade our evolutionary search into random search. 

In line 7, we evalute newly construced individuals. These individuals are being evaluated with the same fitness function used in line 2.

In line 8, we choose which individuals carry on to the next generation. Unlike the parent selection, which is stochastic, this process is usually deterministic. Two common strategies are choosing the best individuals from both parents and offspring, and the age-biased approach, which chooses only from the offspring \citep{eiben2015evolutionarycomputing}. If we choose the latter approach, a problem we might encounter is loosing good solutions, if these good solutions have no children better than themselves. To counter this problem, we can choose to carry over a few of the best solutions into the next generation without changing them. The property of never loosing the best solutions between generations is called elitism \citep{cupic2019evolucijskoracunarstvo}.